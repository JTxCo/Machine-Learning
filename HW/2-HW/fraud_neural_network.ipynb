{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch can be installed with the interactive selector:\n",
    "# https://pytorch.org/get-started/locally/#windows-anaconda\n",
    "\n",
    "# Note the GPU version requires cuda 12.1\n",
    "# NOT cuda 12.3 (the latest version as of 2/1/24)\n",
    "# Can be found here: https://developer.nvidia.com/cuda-12-1-0-download-archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Here are some tools for gpu usage if you want to play with it:\n",
    "# You can check if you have gpu setup and available here:\n",
    "#print(torch.version.cuda)\n",
    "#print(torch.cuda.is_available())\n",
    "\n",
    "# However, in this case the gpu will likely be slower\n",
    "# If you want to try it out uncomment this line, and then a few lines in the training section\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Load data, but skip the header\n",
    "dataset = np.loadtxt('card_transdata.csv', delimiter=',', skiprows = 1, dtype=np.float32)\n",
    "\n",
    "# get the number of data points and number of features\n",
    "[num_datums, num_features] = dataset.shape\n",
    "\n",
    "# The number of features is actually 1 less, because one of the columns is dedicated to the label\n",
    "num_features -= 1\n",
    "\n",
    "# Shuffle the data in case somebody has it in an ordered list\n",
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now discretize for training, evaluating, validating\n",
    "training_ratio = 0.7\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "num_train = round(num_datums * training_ratio)\n",
    "num_valid = round(num_datums * validation_ratio)\n",
    "num_test = round(num_datums * test_ratio)\n",
    "\n",
    "# Create all of the split datasets as numpy arrays\n",
    "X_training_np = dataset[0:num_train, 0:num_features]\n",
    "y_training_np = dataset[0:num_train, -1]\n",
    "\n",
    "X_validation_np = dataset[num_train:num_train+num_valid, 0:num_features]\n",
    "y_validation_np = dataset[num_train:num_train+num_valid, -1]\n",
    "\n",
    "X_test_np = dataset[num_train+num_valid:, 0:num_features]\n",
    "y_test_np = dataset[num_train+num_valid:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy arrays into torch tensors (pretty much the same thing)\n",
    "X_training = torch.from_numpy(X_training_np)\n",
    "y_training = torch.from_numpy(y_training_np).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our network\n",
    "neural_network = torch.nn.Sequential(\n",
    "    torch.nn.Linear(num_features,12),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(12,8),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(8,1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Another approach that is easy to modify number of hidden_layers:\n",
    "#num_hidden_layers = 4\n",
    "#num_hidden_nodes = 12\n",
    "#\n",
    "#initial_layer = torch.nn.Linear(num_features, num_hidden_nodes)\n",
    "#layer_list = [initial_layer]\n",
    "#\n",
    "#for i in range(num_hidden_layers-1):\n",
    "#    layer_list.append( torch.nn.ReLU() )\n",
    "#    layer_list.append( torch.nn.Linear(num_hidden_nodes,num_hidden_nodes))\n",
    "#\n",
    "#layer_list.append( torch.nn.ReLU() )\n",
    "#layer_list.append( torch.nn.Linear(num_hidden_nodes, 1))\n",
    "#layer_list.append( torch.nn.Sigmoid() )\n",
    "#\n",
    "#neural_network = torch.nn.Sequential(*layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define other parameters of the network\n",
    "loss_function = torch.nn.BCELoss() # Binary cross entropy\n",
    "optimizer = torch.optim.Adam(neural_network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to try using the gpu then uncomment here:\n",
    "# Send our tensors to the gpu if it is available\n",
    "#X_training = X_training.to(device)\n",
    "#y_training = y_training.to(device)\n",
    "\n",
    "# Send the model to the gpu\n",
    "#neural_network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model\n",
    "\n",
    "# NOTE: Something cool about pytorch is that it is dynamically updating the model, so\n",
    "# if you interrupt the script it saves the models current state and you can move on to\n",
    "# validating\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 1000\n",
    "num_batches = round(num_train/batch_size)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    t = time.time() # Measure the time of the epoch\n",
    "    for batch in range(num_batches):\n",
    "        # Get a batch of the training data\n",
    "        X_batch = X_training[batch*batch_size:(batch+1)*batch_size]\n",
    "        y_batch = y_training[batch*batch_size:(batch+1)*batch_size]\n",
    "\n",
    "        # Deploy the model\n",
    "        y_prediction = neural_network(X_batch)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(y_prediction, y_batch)\n",
    "\n",
    "        # Back propogation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Compute the time of the epoch\n",
    "    elapsed_time = time.time() - t\n",
    "\n",
    "    # Print results of epoch\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} completed in {elapsed_time:.2f}s, loss {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "# Convert the data to tensors\n",
    "X_validation = torch.from_numpy(X_validation_np)\n",
    "y_valdation = torch.from_numpy(y_validation_np).reshape(-1,1)\n",
    "\n",
    "# Run the model\n",
    "y_prediction = neural_network(X_validation)\n",
    "# Round the results\n",
    "y_prediction = y_prediction.round()\n",
    "\n",
    "# See how many are different\n",
    "num_matches = sum(y_prediction==y_valdation)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = float(num_matches/num_valid)\n",
    "\n",
    "print(f\"Accuracy {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T TOUCH THIS UNTIL YOU ARE DONE TUNING YOUR HYPERPARAMETERS\n",
    "# Convert the data to tensors\n",
    "#X_test = torch.from_numpy(X_test_np)\n",
    "#y_test = torch.from_numpy(y_test_np).reshape(-1,1)\n",
    "\n",
    "# Run the model\n",
    "#y_prediction = neural_network(X_test)\n",
    "# Round the results\n",
    "#y_prediction = y_prediction.round()\n",
    "\n",
    "# See how many are different\n",
    "#num_matches = sum(y_prediction==y_test)\n",
    "\n",
    "# Compute accuracy\n",
    "#accuracy = float(num_matches/num_test)\n",
    "\n",
    "#print(f\"Final Accuracy {accuracy:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
